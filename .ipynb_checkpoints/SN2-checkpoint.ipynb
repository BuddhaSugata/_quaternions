{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd9d047-6c91-4cc8-9cbf-c1a9d9dc5597",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Unimetry Roughness Pipeline — ALL-IN-ONE (v6)\n",
    "\n",
    "Features:\n",
    "- Robust loader for Pantheon+ (whitespace .dat or CSV), auto-detects columns.\n",
    "- Options: prefer zHD vs zCMB; z-min cut; optional peculiar-velocity error term.\n",
    "- Baseline ΛCDM fit (Ωm, M).\n",
    "- ΛCDM + piecewise-constant Δμ(z) with smoothness prior (2nd-difference); \n",
    "  prints bin counts & percentages; saves bin_summary.csv; plots with % labels.\n",
    "- 1-parameter template model Δμ(z) = A f(z) with several f(z) options;\n",
    "  prints A ± σ(A), AIC/BIC, Δχ²; plots Δμ(z) and residuals.\n",
    "- Sky map of SN positions: HEALPix Mollweide (if healpy available) or Matplotlib fallback.\n",
    "\n",
    "Usage:\n",
    "  - Set DATA_PATH to your Pantheon+ table (e.g., Pantheon+SH0ES.dat).\n",
    "  - Run: python unimetry_roughness_pipeline.py\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional: HEALPix for CMB-style maps\n",
    "try:\n",
    "    import healpy as hp\n",
    "    HAVE_HEALPY = True\n",
    "except Exception:\n",
    "    HAVE_HEALPY = False\n",
    "\n",
    "# ====================== CONFIG ======================\n",
    "DATA_PATH = Path(\"./Pantheon+SH0ES.dat\")   # path to Pantheon+ table\n",
    "\n",
    "# Redshift handling\n",
    "PREFER_ZHD = False      # if True, prefer zHD over zCMB\n",
    "Z_MIN = 0.0             # redshift cut: use only z >= Z_MIN\n",
    "ADD_PEC_ERR = False     # include peculiar-velocity error term using VPECERR if present\n",
    "PEC_Z_CLIP = 0.003      # avoid blow-up near z=0 when computing sigma_mu_pec\n",
    "\n",
    "# Roughness (multi-bin) model\n",
    "Z_BINS = np.array([0.0,0.01,0.02,0.03,0.04,0.96,2.0])\n",
    "LAMBDA_SMOOTH = 1.0     # smoothness strength (2nd-difference Tikhonov)\n",
    "SIGMA_FLOOR = 0.12      # floor for sigma_mu if absent\n",
    "\n",
    "# Distances\n",
    "NINT = 600              # trapezoid integration resolution per z\n",
    "SUPPRESS_WARNINGS = True\n",
    "\n",
    "# Sky-map config\n",
    "NSIDE = 16              # HEALPix resolution (12*NSIDE^2 pixels)\n",
    "\n",
    "# Template (1-parameter) model defaults\n",
    "TEMPLATE_KIND = \"z_over_zplus\"   # options: z_over_zplus, ramp_exp, log1pz, power_sat\n",
    "TEMPLATE_Z0   = 0.30             # shape scale\n",
    "TEMPLATE_P    = 1.5              # shape power (for ramp_exp)\n",
    "TEMPLATE_BETA = 1.2              # exponent (for power_sat)\n",
    "\n",
    "# =================== CONSTANTS ======================\n",
    "c_km_s = 299792.458\n",
    "if SUPPRESS_WARNINGS:\n",
    "    warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# ===================== LOADER =======================\n",
    "def _read_any(path: Path) -> pd.DataFrame:\n",
    "    try:\n",
    "        df = pd.read_table(path, comment='#', sep=r\"\\s+\", engine=\"python\")\n",
    "        if len(df.columns) == 1:\n",
    "            df = pd.read_csv(path, comment='#')\n",
    "        return df\n",
    "    except Exception:\n",
    "        try:\n",
    "            return pd.read_csv(path, comment='#')\n",
    "        except Exception:\n",
    "            return pd.read_csv(path, delim_whitespace=True, comment='#')\n",
    "\n",
    "def load_sn_table(path: Path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    df = _read_any(path)\n",
    "\n",
    "    if len(df.columns) == 1:\n",
    "        df = pd.read_table(path, comment='#', sep=r\"\\s+\", engine=\"python\")\n",
    "\n",
    "    cols_lower = {c.lower().strip(): c for c in df.columns}\n",
    "\n",
    "    def pick(*names):\n",
    "        for n in names:\n",
    "            key = n.lower()\n",
    "            if key in cols_lower:\n",
    "                return cols_lower[key]\n",
    "        return None\n",
    "\n",
    "    # choose z column by preference\n",
    "    if PREFER_ZHD:\n",
    "        zcol = pick('zhd','zcmb','z')\n",
    "    else:\n",
    "        zcol = pick('zcmb','zhd','z')\n",
    "\n",
    "    mucol  = pick('mu', 'mu_sh0es', 'distmod', 'm_b_corr', 'mb_corr', 'mb')\n",
    "    sigcol = pick('mu_err','sigma_mu','mu_sh0es_err_diag','m_b_corr_err_diag','dmu','dmb','merr')\n",
    "    vperr_col = pick('vpecerr','vpec_err','sigma_vpec')\n",
    "\n",
    "    if zcol is None or mucol is None:\n",
    "        raise ValueError(f\"Could not find essential columns.\\n\"\n",
    "                         f\"Have columns: {list(df.columns)}\\n\"\n",
    "                         f\"Need some of zCMB/zHD/z and mu or MU_SH0ES/m_b_corr.\")\n",
    "\n",
    "    out = pd.DataFrame()\n",
    "    out['z'] = df[zcol].astype(float)\n",
    "    out['mu_like'] = df[mucol].astype(float)\n",
    "    if sigcol is not None:\n",
    "        out['sigma_mu'] = df[sigcol].astype(float).clip(lower=SIGMA_FLOOR)\n",
    "        sigma_src = sigcol\n",
    "    else:\n",
    "        out['sigma_mu'] = SIGMA_FLOOR\n",
    "        sigma_src = f\"floor={SIGMA_FLOOR}\"\n",
    "\n",
    "    # optional peculiar-velocity error contribution\n",
    "    if ADD_PEC_ERR and (vperr_col is not None):\n",
    "        zv = np.clip(out['z'].values, PEC_Z_CLIP, None)\n",
    "        sigma_v = df[vperr_col].astype(float).values\n",
    "        sigma_mu_pec = (5.0/np.log(10.0)) * (sigma_v / (c_km_s * zv))\n",
    "        out['sigma_mu'] = np.sqrt(out['sigma_mu'].values**2 + sigma_mu_pec**2)\n",
    "\n",
    "    racol = pick('ra','ra_deg')\n",
    "    decol = pick('dec','dec_deg')\n",
    "    out['ra']  = df[racol].astype(float) if racol else np.nan\n",
    "    out['dec'] = df[decol].astype(float) if decol else np.nan\n",
    "\n",
    "    # clean & cut\n",
    "    out = out.replace([np.inf,-np.inf], np.nan).dropna(subset=['z','mu_like','sigma_mu'])\n",
    "    out = out[(out['z']>=Z_MIN) & (out['z']<=2.0)].sort_values('z').reset_index(drop=True)\n",
    "\n",
    "    print(f\"Loaded {len(out)} SNe from {path.name}\")\n",
    "    print(f\"Using z from '{zcol}', mu-like from '{mucol}', sigma from '{sigma_src}'\")\n",
    "    if ADD_PEC_ERR and (vperr_col is not None):\n",
    "        print(f\"Including peculiar-velocity error term from '{vperr_col}' (z clip {PEC_Z_CLIP})\")\n",
    "    return out\n",
    "\n",
    "# =================== COSMOLOGY ======================\n",
    "def E_z(z, Om): return np.sqrt(Om*(1+z)**3 + (1-Om))\n",
    "\n",
    "def comoving_distance(z, Om, H0=70.0):\n",
    "    z = float(z)\n",
    "    zg = np.linspace(0.0, z, NINT)\n",
    "    Ez = E_z(zg, Om)\n",
    "    return (c_km_s/H0) * np.trapezoid(1.0/Ez, zg)\n",
    "\n",
    "def lum_distance(z, Om, H0=70.0): return (1+z)*comoving_distance(z, Om, H0)\n",
    "\n",
    "def mu_theory(z, Om, M):\n",
    "    Dl = np.array([lum_distance(zi, Om) for zi in np.atleast_1d(z)])\n",
    "    return 5.0*np.log10(np.clip(Dl,1e-6,None)) + M\n",
    "\n",
    "# ==================== BASELINE ======================\n",
    "def fit_lcdm(sn_df, Om_grid=np.linspace(0.05,0.6,200)):\n",
    "    y = sn_df['mu_like'].values\n",
    "    w = 1.0/(sn_df['sigma_mu'].values**2)\n",
    "    best=None\n",
    "    for Om in Om_grid:\n",
    "        mu0 = 5.0*np.log10(np.array([lum_distance(z,Om) for z in sn_df['z'].values]))\n",
    "        M = np.sum(w*(y-mu0))/np.sum(w)            # optimal M\n",
    "        r = y - (mu0 + M)\n",
    "        chi2 = np.sum(w*r*r)\n",
    "        if best is None or chi2<best['chi2']:\n",
    "            best={'Om':float(Om),'M':float(M),'chi2':float(chi2)}\n",
    "    N = len(y); k = 2\n",
    "    best['dof']=int(N-k); best['chi2_red']=best['chi2']/max(1,best['dof'])\n",
    "    best['AIC'] = best['chi2'] + 2*k\n",
    "    best['BIC'] = best['chi2'] + k*np.log(N)\n",
    "    return best\n",
    "\n",
    "# ================= MULTI-BIN ROUGHNESS ==============\n",
    "def design_matrix_bins(z, edges):\n",
    "    B = np.zeros((len(z), len(edges)-1))\n",
    "    for j in range(len(edges)-1):\n",
    "        m = (z>=edges[j]) & (z<edges[j+1]); B[m,j]=1.0\n",
    "    B[z>=edges[-1]-1e-10, -1]=1.0\n",
    "    return B\n",
    "\n",
    "def fit_lcdm_with_roughness(sn_df, edges, lam=1.0, Om_grid=np.linspace(0.05,0.6,120)):\n",
    "    z=sn_df['z'].values; y=sn_df['mu_like'].values; w=1.0/(sn_df['sigma_mu'].values**2)\n",
    "    B = design_matrix_bins(z, edges); K=B.shape[1]\n",
    "\n",
    "    # Precompute normal matrix (Om-independent) and prior\n",
    "    X = np.column_stack([np.ones_like(y), B])\n",
    "    W = np.diag(w)\n",
    "    A = X.T @ W @ X\n",
    "\n",
    "    D2 = np.zeros((K-2, K))\n",
    "    for i in range(K-2): D2[i,i:i+3] = [1,-2,1]\n",
    "    RtR = D2.T @ D2\n",
    "\n",
    "    R = np.zeros((K+1, K+1))\n",
    "    R[1:,1:] = lam*RtR\n",
    "\n",
    "    cov_theta = np.linalg.inv(A + R)\n",
    "\n",
    "    best=None\n",
    "    for Om in Om_grid:\n",
    "        mu0 = 5.0*np.log10(np.array([lum_distance(zi,Om) for zi in z]))\n",
    "        b = X.T @ W @ (y - mu0)\n",
    "        theta = np.linalg.solve(A + R, b)\n",
    "        M = theta[0]; delta = theta[1:]\n",
    "        r = y - (mu0 + M + B@delta)\n",
    "        chi2 = float(np.sum(w*r*r) + lam*float(delta@RtR@delta))\n",
    "        if best is None or chi2<best['chi2']:\n",
    "            best={'Om':float(Om),'M':float(M),'delta':delta,'bin_edges':edges,'chi2':chi2}\n",
    "\n",
    "    N = len(y); k = 2 + len(best['delta'])\n",
    "    best['dof']=int(N-k); best['chi2_red']=best['chi2']/max(1,best['dof'])\n",
    "    var_theta = np.diag(cov_theta)\n",
    "    best['delta_err'] = np.sqrt(var_theta[1:])\n",
    "    best['AIC'] = best['chi2'] + 2*k\n",
    "    best['BIC'] = best['chi2'] + k*np.log(N)\n",
    "    return best\n",
    "\n",
    "# ============== 1-PARAM TEMPLATE ROUGHNESS ==========\n",
    "def f_template(z, kind=\"z_over_zplus\", z0=0.25, p=1.5, beta=1.0):\n",
    "    z = np.asarray(z, float)\n",
    "    if kind == \"z_over_zplus\":\n",
    "        f = z / (z + z0)\n",
    "    elif kind == \"ramp_exp\":\n",
    "        f = 1.0 - np.exp(- (z / z0)**p)\n",
    "    elif kind == \"log1pz\":\n",
    "        # normalize by log1p(1+z0) just to keep typical scale ~1 around z~z0\n",
    "        f = np.log1p(z) / np.log1p(1.0 + z0)\n",
    "    elif kind == \"power_sat\":\n",
    "        f = (z / (z + z0))**beta\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown template kind: {kind}\")\n",
    "    return f\n",
    "\n",
    "def fit_lcdm_with_template(sn_df,\n",
    "                           kind=\"z_over_zplus\",\n",
    "                           z0=0.25, p=1.5, beta=1.0,\n",
    "                           Om_grid=np.linspace(0.05, 0.6, 200)):\n",
    "    \"\"\"Fit ΛCDM + A f(z) with ONE amplitude parameter A (plus M, Om).\n",
    "       f is centered (weighted) to avoid degeneracy with constant M.\n",
    "    \"\"\"\n",
    "    z = sn_df['z'].values\n",
    "    y = sn_df['mu_like'].values\n",
    "    w = 1.0 / (sn_df['sigma_mu'].values**2)\n",
    "\n",
    "    f = f_template(z, kind=kind, z0=z0, p=p, beta=beta)\n",
    "    f = f - np.average(f, weights=w)  # weighted centering\n",
    "\n",
    "    best = None\n",
    "    for Om in Om_grid:\n",
    "        mu0 = 5.0*np.log10(np.array([lum_distance(zi, Om) for zi in z]))\n",
    "        X = np.column_stack([np.ones_like(z), f])  # [M, A]\n",
    "        W = np.diag(w)\n",
    "        A_mat = X.T @ W @ X\n",
    "        b_vec = X.T @ W @ (y - mu0)\n",
    "        theta = np.linalg.solve(A_mat, b_vec)\n",
    "        M_hat, A_hat = float(theta[0]), float(theta[1])\n",
    "\n",
    "        resid = y - (mu0 + M_hat + A_hat * f)\n",
    "        chi2  = float(np.sum(w * resid**2))\n",
    "\n",
    "        if (best is None) or (chi2 < best['chi2']):\n",
    "            cov = np.linalg.inv(A_mat)\n",
    "            sigA = float(np.sqrt(cov[1,1]))\n",
    "            best = {'Om':float(Om), 'M': M_hat, 'A': A_hat, 'sigma_A': sigA,\n",
    "                    'chi2': chi2, 'f': f, 'kind': kind, 'z0': z0, 'p': p, 'beta': beta}\n",
    "\n",
    "    N = len(y); k = 3\n",
    "    best['dof'] = int(N - k)\n",
    "    best['chi2_red'] = best['chi2']/max(1,best['dof'])\n",
    "    best['AIC'] = best['chi2'] + 2*k\n",
    "    best['BIC'] = best['chi2'] + k*np.log(N)\n",
    "    return best\n",
    "\n",
    "def compare_models_print(lcdm, rough, templ):\n",
    "    N = lcdm['dof'] + 2\n",
    "    k_lcdm = 2\n",
    "    print(\"\\n=== MODEL COMPARISON ===\")\n",
    "    print(f\"LCDM:    χ²={lcdm['chi2']:.1f}, dof={lcdm['dof']}, χ²_red={lcdm['chi2_red']:.3f}, AIC={lcdm['AIC']:.1f}, BIC={lcdm['BIC']:.1f}\")\n",
    "    print(f\"Rough(K={len(rough['delta'])}): χ²={rough['chi2']:.1f}, dof={rough['dof']}, χ²_red={rough['chi2_red']:.3f}, AIC={rough['AIC']:.1f}, BIC={rough['BIC']:.1f}\")\n",
    "    print(f\"Template(1p): χ²={templ['chi2']:.1f}, dof={templ['dof']}, χ²_red={templ['chi2_red']:.3f}, AIC={templ['AIC']:.1f}, BIC={templ['BIC']:.1f}\")\n",
    "    print(f\"Δχ² (LCDM→Rough)    = {lcdm['chi2']-rough['chi2']:.2f} for {2+len(rough['delta'])-2} extra params\")\n",
    "    print(f\"Δχ² (LCDM→Template) = {lcdm['chi2']-templ['chi2']:.2f} for {3-2} extra params\")\n",
    "\n",
    "# =================== PLOTTING =======================\n",
    "def plot_baseline_and_roughness(sn, lcdm, rough):\n",
    "    z = sn['z'].values; y = sn['mu_like'].values\n",
    "    B = design_matrix_bins(z, rough['bin_edges']); dm = rough['delta']; de = rough['delta_err']\n",
    "    muL = mu_theory(z, lcdm['Om'], lcdm['M'])\n",
    "    muR = mu_theory(z, rough['Om'], rough['M']) + B @ dm\n",
    "\n",
    "    # Residuals (baseline)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.scatter(z, y-muL, s=6, alpha=0.5)\n",
    "    plt.xlabel('z'); plt.ylabel('μ_obs - μ_LCDM'); plt.title('Residuals (baseline)')\n",
    "    plt.tight_layout(); plt.savefig(\"residuals_baseline.png\", dpi=160)\n",
    "\n",
    "    # Δμ(z) step with % annotations and error bars\n",
    "    be = rough['bin_edges']\n",
    "    counts = B.sum(axis=0).astype(int)\n",
    "    total = len(z); perc = counts/total*100.0\n",
    "    zc = 0.5*(be[:-1] + be[1:])\n",
    "\n",
    "    plt.figure(figsize=(9,4.8))\n",
    "    plt.step(be[:-1], dm, where='post')\n",
    "    plt.errorbar(zc, dm, yerr=de, fmt='o', ms=4)\n",
    "    for j in range(len(counts)):\n",
    "        ytext = dm[j] + (0.02 if np.isfinite(dm[j]) else 0.02)\n",
    "        plt.text(zc[j], ytext, f\"{perc[j]:.1f}%\", ha='center', va='bottom')\n",
    "    plt.xlabel('z'); plt.ylabel('Δμ bin (mag)'); plt.title('Inferred roughness Δμ(z)')\n",
    "    plt.tight_layout(); plt.savefig(\"roughness_dmu_bins.png\", dpi=160)\n",
    "\n",
    "    # Residuals (after roughness)\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.scatter(z, y-muR, s=6, alpha=0.5)\n",
    "    plt.xlabel('z'); plt.ylabel('μ_obs - μ_model'); plt.title('Residuals (after roughness)')\n",
    "    plt.tight_layout(); plt.savefig(\"residuals_after.png\", dpi=160)\n",
    "\n",
    "    # Bin summary CSV\n",
    "    df_out = pd.DataFrame({\n",
    "        \"z_left\":  be[:-1],\n",
    "        \"z_right\": be[1:],\n",
    "        \"count\":   counts,\n",
    "        \"percent\": perc,\n",
    "        \"delta_mu\": dm,\n",
    "        \"sigma_delta_mu\": de\n",
    "    })\n",
    "    df_out.to_csv(\"bin_summary.csv\", index=False)\n",
    "    print(\"Saved bin summary -> bin_summary.csv\")\n",
    "\n",
    "def plot_template(sn, lcdm, templ, prefix=\"template\"):\n",
    "    z = sn['z'].values; y = sn['mu_like'].values\n",
    "    f = templ['f']\n",
    "    muT = mu_theory(z, templ['Om'], templ['M']) + templ['A'] * f\n",
    "\n",
    "    # Δμ(z) = A f(z)\n",
    "    idx = np.argsort(z)\n",
    "    plt.figure(figsize=(8.2,4.6))\n",
    "    plt.plot(z[idx], (templ['A']*f)[idx])\n",
    "    plt.xlabel(\"z\"); plt.ylabel(\"Δμ(z) [mag]\")\n",
    "    plt.title(f\"Template: {templ['kind']}  (A = {templ['A']:+.4f} ± {templ['sigma_A']:.4f})\")\n",
    "    plt.tight_layout(); plt.savefig(f\"{prefix}_dmu.png\", dpi=160)\n",
    "\n",
    "    # Residuals after template\n",
    "    plt.figure(figsize=(8.2,5))\n",
    "    plt.scatter(z, y - muT, s=6, alpha=0.5)\n",
    "    plt.xlabel(\"z\"); plt.ylabel(\"μ_obs - μ_model\")\n",
    "    plt.title(\"Residuals after ΛCDM + A f(z)\")\n",
    "    plt.tight_layout(); plt.savefig(f\"{prefix}_resid.png\", dpi=160)\n",
    "\n",
    "# =================== SKY MAPS =======================\n",
    "def save_sky_map_healpy(sn_df, nside=NSIDE, out_png=\"sn_sky_healpy.png\"):\n",
    "    ra = sn_df['ra'].values; dec = sn_df['dec'].values\n",
    "    mask = np.isfinite(ra) & np.isfinite(dec)\n",
    "    if not mask.any():\n",
    "        print(\"No RA/Dec available; skipping HEALPix map.\")\n",
    "        return False\n",
    "    theta = np.deg2rad(90.0 - dec[mask])\n",
    "    phi   = np.deg2rad(ra[mask])\n",
    "    npix = hp.nside2npix(nside)\n",
    "    m = np.zeros(npix, dtype=float)\n",
    "    ipix = hp.ang2pix(nside, theta, phi)\n",
    "    for p in ipix: m[p] += 1.0\n",
    "    hp.mollview(m, title=f\"SN sky distribution (HEALPix NSIDE={nside})\")\n",
    "    plt.savefig(out_png, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"Saved HEALPix sky map -> {out_png}\")\n",
    "    return True\n",
    "\n",
    "def save_sky_map_mollweide_scatter(sn_df, out_png=\"sn_sky_mollweide_scatter.png\"):\n",
    "    ra = sn_df['ra'].values; dec = sn_df['dec'].values\n",
    "    mask = np.isfinite(ra) & np.isfinite(dec)\n",
    "    if not mask.any():\n",
    "        print(\"No RA/Dec available; skipping Mollweide scatter.\")\n",
    "        return False\n",
    "    ra = ra[mask]; dec = dec[mask]\n",
    "    x = np.deg2rad(ra % 360.0); x[x > np.pi] -= 2.0*np.pi; x = -x\n",
    "    y = np.deg2rad(dec)\n",
    "    fig = plt.figure(figsize=(9,5))\n",
    "    ax = fig.add_subplot(111, projection='mollweide')\n",
    "    ax.scatter(x, y, s=6, alpha=0.7)\n",
    "    ax.grid(True)\n",
    "    ax.set_title(\"SN sky distribution (Mollweide scatter)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_png, dpi=160, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"Saved Mollweide scatter -> {out_png}\")\n",
    "    return True\n",
    "\n",
    "# ====================== MAIN ========================\n",
    "def main():\n",
    "    sn = load_sn_table(DATA_PATH)\n",
    "\n",
    "    # Baseline ΛCDM\n",
    "    lcdm = fit_lcdm(sn)\n",
    "\n",
    "    # Multi-bin roughness\n",
    "    rough = fit_lcdm_with_roughness(sn, Z_BINS, LAMBDA_SMOOTH)\n",
    "\n",
    "    # Print results\n",
    "    print(\"\\n=== RESULTS (BASELINE & ROUGHNESS) ===\")\n",
    "    print(f\"LCDM:  chi2={lcdm['chi2']:.1f}, dof={lcdm['dof']}, chi2_red={lcdm['chi2_red']:.3f}, AIC={lcdm['AIC']:.1f}, BIC={lcdm['BIC']:.1f}\")\n",
    "    print(f\"Rough: chi2={rough['chi2']:.1f}, dof={rough['dof']}, chi2_red={rough['chi2_red']:.3f}, AIC={rough['AIC']:.1f}, BIC={rough['BIC']:.1f}\")\n",
    "    print(f\"Δχ² = {lcdm['chi2'] - rough['chi2']:.2f} for {2+len(rough['delta'])-2} extra bins\")\n",
    "\n",
    "    # Plots & bin summary\n",
    "    plot_baseline_and_roughness(sn, lcdm, rough)\n",
    "\n",
    "    # Sky map\n",
    "    made = False\n",
    "    if HAVE_HEALPY:\n",
    "        made = save_sky_map_healpy(sn, nside=NSIDE, out_png=\"sn_sky_healpy.png\")\n",
    "    if not made:\n",
    "        save_sky_map_mollweide_scatter(sn, out_png=\"sn_sky_mollweide_scatter.png\")\n",
    "\n",
    "    # 1-parameter template fit\n",
    "    templ = fit_lcdm_with_template(sn,\n",
    "                                   kind=TEMPLATE_KIND,\n",
    "                                   z0=TEMPLATE_Z0, p=TEMPLATE_P, beta=TEMPLATE_BETA)\n",
    "    print(\"\\n=== 1-PARAM TEMPLATE ===\")\n",
    "    print(f\"Template: {templ['kind']}  (z0={templ['z0']}, p={templ['p']}, beta={templ['beta']})\")\n",
    "    print(f\"Om={templ['Om']:.3f}, A={templ['A']:+.4f} ± {templ['sigma_A']:.4f} mag\")\n",
    "    print(f\"chi2={templ['chi2']:.1f}, dof={templ['dof']}, chi2_red={templ['chi2_red']:.3f}, AIC={templ['AIC']:.1f}, BIC={templ['BIC']:.1f}\")\n",
    "\n",
    "    # Compare all three\n",
    "    compare_models_print(lcdm, rough, templ)\n",
    "    plot_template(sn, lcdm, templ, prefix=f\"template_{templ['kind']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df5842e-38be-4ac5-947c-46ae5e43e87b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
